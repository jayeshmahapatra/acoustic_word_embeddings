{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Core Python, Pandas, and kaldi_io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from collections import Counter,OrderedDict \n",
    "import kaldi_io\n",
    "\n",
    "#Scikit\n",
    "from sklearn import manifold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import pairwise_distances,average_precision_score\n",
    "from sklearn.metrics.pairwise import pairwise_kernels,paired_distances\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "#Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#BigPhoney\n",
    "from big_phoney import BigPhoney\n",
    "\n",
    "\n",
    "#Torch and utilities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset,DataLoader,random_split,ConcatDataset\n",
    "\n",
    "#Import User defined classes\n",
    "from data_helpers import DataHelper\n",
    "from models import SimpleNet\n",
    "from train_test_helpers import accuracy,train_model,evaluate_model,evaluate_model_paper,test_model,plot_learning_curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_list = ['Data/feats_cmvn.ark']\n",
    "#number_list = [9,12,14,18,21,25,27,28]\n",
    "#load_list = ['Data/raw_mfcc_AMI_Segments.%d.scp'%(number) for number in number_list]\n",
    "num_examples = np.Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = DataHelper(load_list,num_examples)\n",
    "dh.load_data()\n",
    "dh.process_data()\n",
    "c,word_to_num,num_to_word = dh.generate_key_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,labels = dh.give_inputs_and_labels()\n",
    "del dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = False\n",
    "if split:\n",
    "    x_trainval,x_test,y_trainval,y_test = train_test_split(inputs, labels, test_size=0.2, random_state=32)\n",
    "    x_train,x_val,y_train,y_val = train_test_split(x_trainval,y_trainval,test_size =0.25, random_state = 32)\n",
    "    x_train,y_train = torch.tensor(x_train,dtype= torch.float),torch.tensor(y_train, dtype= torch.float)\n",
    "    x_val,y_val = torch.tensor(x_val, dtype= torch.float),torch.tensor(y_val, dtype= torch.float)\n",
    "    x_test,y_test = torch.tensor(x_test, dtype= torch.float),torch.tensor(y_test, dtype= torch.float)\n",
    "    print(x_train.shape,y_train.shape)\n",
    "    print(x_val.shape,y_val.shape)\n",
    "    print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = SimpleNet()\n",
    "num_output = len(c.keys())\n",
    "net = SimpleNet(num_output)\n",
    "net = net.float()\n",
    "net.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the best model\n",
    "best_model_path = \"./Models/awe_best_model.pth\"\n",
    "net.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the word_pairs DataFrame\n",
    "wordpairs_df = pd.read_csv('Data/wordpairs_test.txt', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>orthographic_edit_distance</th>\n",
       "      <th>raw_phonetic_edit_distance</th>\n",
       "      <th>filtered_phonetic_edit_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>could</td>\n",
       "      <td>required</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meeting</td>\n",
       "      <td>system</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grippy</td>\n",
       "      <td>submission</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doing</td>\n",
       "      <td>forth</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quite</td>\n",
       "      <td>regular</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70120</th>\n",
       "      <td>connection</td>\n",
       "      <td>liking</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70121</th>\n",
       "      <td>connect</td>\n",
       "      <td>zapping</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70122</th>\n",
       "      <td>colours</td>\n",
       "      <td>proper</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70123</th>\n",
       "      <td>light</td>\n",
       "      <td>mention</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70124</th>\n",
       "      <td>abstract</td>\n",
       "      <td>heavily</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70125 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word_1      word_2  orthographic_edit_distance  \\\n",
       "0           could    required                           6   \n",
       "1         meeting      system                           6   \n",
       "2          grippy  submission                           9   \n",
       "3           doing       forth                           4   \n",
       "4           quite     regular                           6   \n",
       "...           ...         ...                         ...   \n",
       "70120  connection      liking                           9   \n",
       "70121     connect     zapping                           7   \n",
       "70122     colours      proper                           6   \n",
       "70123       light     mention                           7   \n",
       "70124    abstract     heavily                           8   \n",
       "\n",
       "       raw_phonetic_edit_distance  filtered_phonetic_edit_distance  \n",
       "0                               5                                5  \n",
       "1                               5                                5  \n",
       "2                               7                                7  \n",
       "3                               4                                4  \n",
       "4                               7                                7  \n",
       "...                           ...                              ...  \n",
       "70120                           7                                7  \n",
       "70121                           6                                6  \n",
       "70122                           5                                5  \n",
       "70123                           6                                6  \n",
       "70124                           8                                8  \n",
       "\n",
       "[70125 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate all the unique words\n",
    "def words_from_dataframe(dataframe):\n",
    "    wordpairs_list = dataframe[\"word_pairs\"].apply(lambda x: x.strip('()').split(','))\n",
    "    words = [word.strip(' \\'') for wordpair in wordpairs_list for word in wordpair]\n",
    "    words = set(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_embedding_dict(words):\n",
    "    word_embedding_dict = OrderedDict()\n",
    "    #Calculate embeddings\n",
    "    for word in words:\n",
    "        #Find the mfcc features of the acoustic representation of the word in the data\n",
    "        word_features = inputs[np.where(np.isin(labels,word_to_num[word]))]\n",
    "        \n",
    "        #Calculate embeddings for the feature\n",
    "        word_embedding = net.give_embeddings(torch.tensor(word_features, device = dev, dtype=torch.float),dev)\n",
    "        \n",
    "        #If the number of representation is more than one, take the average embedding\n",
    "        word_embedding_dict[word] = np.mean(word_embedding, axis = 0).reshape(1,-1)\n",
    "    \n",
    "    return word_embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embedding_distance(homophone_df,word_embedding_dict,metrics = ['cosine']):\n",
    "\n",
    "    word1_embeddings = None\n",
    "    word2_embeddings = None\n",
    "    \n",
    "    metric_distance_dict = {}\n",
    "    for metric in metrics:\n",
    "        metric_distance_dict[metric] = []\n",
    "        \n",
    "    for row in homophone_df.itertuples():\n",
    "        word1, word2 = map(lambda x: x.strip(' \\''),row.word_pairs.strip('()').split(','))\n",
    "        \n",
    "        for metric in metrics:\n",
    "            metric_distance_dict[metric].append(paired_distances(word_embedding_dict[word1],word_embedding_dict[word2], metric = metric)[0])\n",
    "        \n",
    "        \n",
    "        #if word1_embeddings is None and word2_embeddings is None:\n",
    "        #    word1_embeddings = word_embedding_dict[word1]\n",
    "        #    word2_embeddings = word_embedding_dict[word2]\n",
    "        #else:\n",
    "        #    word1_embeddings = np.vstack((word1_embeddings, word_embedding_dict[word1]))\n",
    "        #    word2_embeddings = np.vstack((word2_embeddings, word_embedding_dict[word2]))\n",
    "            \n",
    "        \n",
    "\n",
    "    #Calculate the distance\n",
    "    #print(word1_embeddings.shape)\n",
    "    for metric in metrics:\n",
    "        #metric_distance = paired_distances(word1_embeddings,word2_embeddings, metric = metric)\n",
    "        homophone_df.insert(len(homophone_df.columns),\"%s_distance\"%(metric), metric_distance_dict[metric], True)\n",
    "    \n",
    "    return homophone_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_nearest_neighbours_on_embeddings(word_embedding_dict, n_neighbours = 10, metric = 'cosine', split = False):\n",
    "    \n",
    "    embeddings = None\n",
    "    \n",
    "    embeddings = np.stack(list(word_embedding_dict.values())).squeeze()\n",
    "    \n",
    "    print('Calculating Nearest Neighbours')\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbours, algorithm='brute',metric = metric, n_jobs = 4).fit(embeddings)\n",
    "    distances,indices = nbrs.kneighbors(embeddings)\n",
    "    \n",
    "    columns = [\"word\",\"neighbours\"]\n",
    "    #nearest_neighbours_df = pd.DataFrame(columns = columns)\n",
    "    \n",
    "    words = list(word_embedding_dict.keys())\n",
    "    print('num of words %d'%(len(words)))\n",
    "    \n",
    "    \n",
    "    nearest_neighbours_df = pd.DataFrame(columns = columns)\n",
    "    \n",
    "    for i,word in enumerate(word_embedding_dict.keys()):\n",
    "        \n",
    "        neighbours = ','.join([words[indices[i,j]] for j in range(indices.shape[1]) if words[indices[i,j]]!= word])\n",
    "        #print(neighbours)\n",
    "        row = pd.DataFrame(np.array([[word],[neighbours]]).T, columns = columns)\n",
    "        nearest_neighbours_df = nearest_neighbours_df.append(row)\n",
    "        \n",
    "    \n",
    "    #pd.concat([pd.DataFrame(np.array([[word],[','.join([words[indices[i,j]] for j in range(indices.shape[1]) if words[indices[i,j]]!=word ])]]).T, columns = columns) for i,word in enumerate(word_embedding_dict.keys())])\n",
    "    \n",
    "    if split:\n",
    "        neighbour_col_names = [\"neighbour_%d\"%(i) for i in range(n_neighbours)]\n",
    "        nearest_neighbours_df[neighbour_col_names] = nearest_neighbours_df.neighbours.str.split(',', expand = True )\n",
    "        nearest_neighbours_df.drop(columns = [\"neighbours\"],inplace = True)\n",
    "    \n",
    "    \n",
    "    #Reset index\n",
    "    nearest_neighbours_df = nearest_neighbours_df.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return nearest_neighbours_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_dict = generate_word_embedding_dict(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_dict = generate_word_embedding_dict(c.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Data/word_embedding_dict.npy\",word_embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_nearest_neighbours = give_nearest_neighbours_on_embeddings(word_embedding_dict, 10,'cosine', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = calculate_embedding_distance(wordpairs_df,word_embedding_dict,metrics = ['cosine', 'euclidean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.scatterplot(\n",
    "    x=\"phonetic_edit_distance\", y=\"%s_distance\"%(metrics[0]),\n",
    "    #hue=\"Word\",\n",
    "    data=df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.5)\n",
    "g.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.scatterplot(\n",
    "    x=\"phonetic_edit_distance\", y=\"%s_distance\"%(metrics[1]),\n",
    "    #hue=\"Word\",\n",
    "    data=df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.5)\n",
    "g.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('phonetic_edit_distance', as_index = False).agg(['mean', 'count', 'std'], index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.scatterplot(\n",
    "    x=\"phonetic_edit_distance\", y=\"%s_distance\"%(metrics[0]),\n",
    "    #hue=\"Word\",\n",
    "    data=df.groupby('phonetic_edit_distance', as_index = False).mean(),\n",
    "    legend=\"full\",\n",
    "    alpha=0.5)\n",
    "plt.ylabel('average cosine distance')\n",
    "#g.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.scatterplot(\n",
    "    x=\"phonetic_edit_distance\", y=\"%s_distance\"%(metrics[1]),\n",
    "    #hue=\"Word\",\n",
    "    data=df.groupby('phonetic_edit_distance', as_index = False).mean(),\n",
    "    legend=\"full\",\n",
    "    alpha=0.5)\n",
    "plt.ylabel('average euclidean distance')\n",
    "#g.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the homophones_df and split it word pairs into indiviudal columns\n",
    "homophones = pd.read_csv('Data/homophones.txt')\n",
    "column_names = ['word_1','word_2']\n",
    "homophones[column_names] = homophones.word_pairs.str.strip('()').str.split(',', expand = True)\n",
    "homophones[\"word_1\"] = homophones.word_1.str.strip(' \\'\\'')\n",
    "homophones[\"word_2\"] = homophones.word_2.str.strip(' \\'')\n",
    "del homophones[\"word_pairs\"]\n",
    "cols = list(homophones)\n",
    "# move the column to head of list using index, pop and insert\n",
    "cols.insert(0, cols.pop(cols.index('word_2')))\n",
    "cols.insert(0, cols.pop(cols.index('word_1')))\n",
    "homophones = homophones.loc[:, cols]\n",
    "homophones.to_csv('Data/homophones_expanded.txt', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start of Nearest Neighbour Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the nearest neighbours based on embeddings and orthographic/phonetic representation\n",
    "em_cosine_nn = pd.read_csv('Data/em_nearest_neighbours.txt')\n",
    "edit_distance_nn = pd.read_csv('Data/edit_nearest_neighbours.txt')\n",
    "sim_distance_nn = pd.read_csv('Data/sim_nearest_neighbours.txt')\n",
    "homophones = pd.read_csv('Data/homophones.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>neighbours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mmhmm</td>\n",
       "      <td>regional,mhhmm,hmmmm,parallel,bumps,mmmmmm,mmm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thank</td>\n",
       "      <td>thinked,think,thing,thingll,pinned,seemed,hang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uhhuh</td>\n",
       "      <td>avril,avocado,crack,liger,addon,mmhmm,whatnot,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>already</td>\n",
       "      <td>roller,cloak,coordinate,laundry,figleaf,orally...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>analyse</td>\n",
       "      <td>penlight,anonymous,fabulous,analysed,dialects,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9969</th>\n",
       "      <td>ponnen</td>\n",
       "      <td>problem,scrollbutton,probabl,profitmargin,trun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>vanna</td>\n",
       "      <td>dimensional,banana,bananabando,bananarama,frui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>origi</td>\n",
       "      <td>exhibit,misplace,hourish,upstairs,azerty,robin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>refresh</td>\n",
       "      <td>wordperfect,imagination,demonstration,weixuns,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>thataway</td>\n",
       "      <td>plotters,other,hardish,outline,parallelogram,f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9974 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word                                         neighbours\n",
       "0        mmhmm  regional,mhhmm,hmmmm,parallel,bumps,mmmmmm,mmm...\n",
       "1        thank  thinked,think,thing,thingll,pinned,seemed,hang...\n",
       "2        uhhuh  avril,avocado,crack,liger,addon,mmhmm,whatnot,...\n",
       "3      already  roller,cloak,coordinate,laundry,figleaf,orally...\n",
       "4      analyse  penlight,anonymous,fabulous,analysed,dialects,...\n",
       "...        ...                                                ...\n",
       "9969    ponnen  problem,scrollbutton,probabl,profitmargin,trun...\n",
       "9970     vanna  dimensional,banana,bananabando,bananarama,frui...\n",
       "9971     origi  exhibit,misplace,hourish,upstairs,azerty,robin...\n",
       "9972   refresh  wordperfect,imagination,demonstration,weixuns,...\n",
       "9973  thataway  plotters,other,hardish,outline,parallelogram,f...\n",
       "\n",
       "[9974 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_cosine_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>orthographic</th>\n",
       "      <th>raw_phonetic</th>\n",
       "      <th>filtered_phonetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cheapie</td>\n",
       "      <td>('cheaply', 'cheapy', 'cheaps', 'cheaper', 'ch...</td>\n",
       "      <td>('cheapy', 'cheap', 'cheaply', 'chippy', 'chee...</td>\n",
       "      <td>('cheapy', 'cheap', 'chippy', 'cheaper', 'chea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conjunction</td>\n",
       "      <td>('connection', 'consumption', 'conjunct', 'con...</td>\n",
       "      <td>('conjunctural', 'connection', 'consumption', ...</td>\n",
       "      <td>('consumption', 'connection', 'conjunctural', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nicer</td>\n",
       "      <td>('univer', 'tiger', 'nicked', 'timer', 'ticker...</td>\n",
       "      <td>('minor', 'guyss', 'night', 'wiper', 'wider', ...</td>\n",
       "      <td>('guyss', 'night', 'dicier', 'lesser', 'nines'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ourselves</td>\n",
       "      <td>('yourselves', 'ourself', 'observed', 'solves'...</td>\n",
       "      <td>('ourself', 'cells', 'yourselves', 'yourself',...</td>\n",
       "      <td>('ourself', 'sells', 'yourself', 'themselves',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>temporarily</td>\n",
       "      <td>('temporary', 'temporal', 'separately', 'tempe...</td>\n",
       "      <td>('temporal', 'necessarily', 'temporary', 'simi...</td>\n",
       "      <td>('temporary', 'temporal', 'temperature', 'nece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9969</th>\n",
       "      <td>global</td>\n",
       "      <td>('globally', 'globe', 'globby', 'loyal', 'loca...</td>\n",
       "      <td>('globally', 'local', 'mobile', 'label', 'glob...</td>\n",
       "      <td>('globally', 'mobile', 'globe', 'local', 'labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>hearing</td>\n",
       "      <td>('bearing', 'wearing', 'healing', 'gearing', '...</td>\n",
       "      <td>('healing', 'keyring', 'heating', 'raring', 'h...</td>\n",
       "      <td>('heating', 'keyring', 'healing', 'seeking', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>slidebar</td>\n",
       "      <td>('slider', 'slides', 'linear', 'slideaway', 's...</td>\n",
       "      <td>('sliding', 'slide', 'sliders', 'slides', 'sli...</td>\n",
       "      <td>('sliders', 'slide', 'sliding', 'slider', 'sli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>dedicated</td>\n",
       "      <td>('dedicate', 'educated', 'delicate', 'indicate...</td>\n",
       "      <td>('indicated', 'edited', 'dedicate', 'dominated...</td>\n",
       "      <td>('indicated', 'dedicate', 'edited', 'educated'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>pathetic</td>\n",
       "      <td>('aesthetic', 'magnetic', 'partic', 'cosmetic'...</td>\n",
       "      <td>('kinetic', 'aesthetic', 'generic', 'plastic',...</td>\n",
       "      <td>('aesthetic', 'kinetic', 'putting', 'generic',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9974 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word                                       orthographic  \\\n",
       "0         cheapie  ('cheaply', 'cheapy', 'cheaps', 'cheaper', 'ch...   \n",
       "1     conjunction  ('connection', 'consumption', 'conjunct', 'con...   \n",
       "2           nicer  ('univer', 'tiger', 'nicked', 'timer', 'ticker...   \n",
       "3       ourselves  ('yourselves', 'ourself', 'observed', 'solves'...   \n",
       "4     temporarily  ('temporary', 'temporal', 'separately', 'tempe...   \n",
       "...           ...                                                ...   \n",
       "9969       global  ('globally', 'globe', 'globby', 'loyal', 'loca...   \n",
       "9970      hearing  ('bearing', 'wearing', 'healing', 'gearing', '...   \n",
       "9971     slidebar  ('slider', 'slides', 'linear', 'slideaway', 's...   \n",
       "9972    dedicated  ('dedicate', 'educated', 'delicate', 'indicate...   \n",
       "9973     pathetic  ('aesthetic', 'magnetic', 'partic', 'cosmetic'...   \n",
       "\n",
       "                                           raw_phonetic  \\\n",
       "0     ('cheapy', 'cheap', 'cheaply', 'chippy', 'chee...   \n",
       "1     ('conjunctural', 'connection', 'consumption', ...   \n",
       "2     ('minor', 'guyss', 'night', 'wiper', 'wider', ...   \n",
       "3     ('ourself', 'cells', 'yourselves', 'yourself',...   \n",
       "4     ('temporal', 'necessarily', 'temporary', 'simi...   \n",
       "...                                                 ...   \n",
       "9969  ('globally', 'local', 'mobile', 'label', 'glob...   \n",
       "9970  ('healing', 'keyring', 'heating', 'raring', 'h...   \n",
       "9971  ('sliding', 'slide', 'sliders', 'slides', 'sli...   \n",
       "9972  ('indicated', 'edited', 'dedicate', 'dominated...   \n",
       "9973  ('kinetic', 'aesthetic', 'generic', 'plastic',...   \n",
       "\n",
       "                                      filtered_phonetic  \n",
       "0     ('cheapy', 'cheap', 'chippy', 'cheaper', 'chea...  \n",
       "1     ('consumption', 'connection', 'conjunctural', ...  \n",
       "2     ('guyss', 'night', 'dicier', 'lesser', 'nines'...  \n",
       "3     ('ourself', 'sells', 'yourself', 'themselves',...  \n",
       "4     ('temporary', 'temporal', 'temperature', 'nece...  \n",
       "...                                                 ...  \n",
       "9969  ('globally', 'mobile', 'globe', 'local', 'labe...  \n",
       "9970  ('heating', 'keyring', 'healing', 'seeking', '...  \n",
       "9971  ('sliders', 'slide', 'sliding', 'slider', 'sli...  \n",
       "9972  ('indicated', 'dedicate', 'edited', 'educated'...  \n",
       "9973  ('aesthetic', 'kinetic', 'putting', 'generic',...  \n",
       "\n",
       "[9974 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
