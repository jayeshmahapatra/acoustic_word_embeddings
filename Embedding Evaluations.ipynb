{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Core Python, Pandas, and kaldi_io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from collections import Counter,OrderedDict \n",
    "import kaldi_io\n",
    "\n",
    "#Scikit\n",
    "from sklearn import manifold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import pairwise_distances,average_precision_score\n",
    "from sklearn.metrics.pairwise import pairwise_kernels,paired_distances\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "#Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#BigPhoney\n",
    "from big_phoney import BigPhoney\n",
    "\n",
    "\n",
    "#Torch and utilities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset,DataLoader,random_split,ConcatDataset\n",
    "\n",
    "#Import User defined classes\n",
    "from data_helpers import DataHelper\n",
    "from models import SimpleNet\n",
    "from train_test_helpers import accuracy,train_model,evaluate_model,evaluate_model_paper,test_model,plot_learning_curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_list = ['Data/feats_cmvn.ark']\n",
    "#number_list = [9,12,14,18,21,25,27,28]\n",
    "#load_list = ['Data/raw_mfcc_AMI_Segments.%d.scp'%(number) for number in number_list]\n",
    "num_examples = np.Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = DataHelper(load_list,num_examples)\n",
    "dh.load_data()\n",
    "dh.process_data()\n",
    "c,word_to_num,num_to_word = dh.generate_key_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,labels = dh.give_inputs_and_labels()\n",
    "del dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = False\n",
    "if split:\n",
    "    x_trainval,x_test,y_trainval,y_test = train_test_split(inputs, labels, test_size=0.2, random_state=32)\n",
    "    x_train,x_val,y_train,y_val = train_test_split(x_trainval,y_trainval,test_size =0.25, random_state = 32)\n",
    "    x_train,y_train = torch.tensor(x_train,dtype= torch.float),torch.tensor(y_train, dtype= torch.float)\n",
    "    x_val,y_val = torch.tensor(x_val, dtype= torch.float),torch.tensor(y_val, dtype= torch.float)\n",
    "    x_test,y_test = torch.tensor(x_test, dtype= torch.float),torch.tensor(y_test, dtype= torch.float)\n",
    "    print(x_train.shape,y_train.shape)\n",
    "    print(x_val.shape,y_val.shape)\n",
    "    print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = SimpleNet()\n",
    "num_output = len(c.keys())\n",
    "net = SimpleNet(num_output)\n",
    "net = net.float()\n",
    "net.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the best model\n",
    "best_model_path = \"./Models/awe_best_model.pth\"\n",
    "net.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the word_pairs DataFrame\n",
    "wordpairs_df = pd.read_csv('Data/wordpairs_test.txt', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordpairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_homophones = wordpairs_df[wordpairs_df[\"phonetic_edit_distance\"]<2]\n",
    "#filtered_homophones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate all the unique words\n",
    "def words_from_dataframe(dataframe):\n",
    "    wordpairs_list = dataframe[\"word_pairs\"].apply(lambda x: x.strip('()').split(','))\n",
    "    words = [word.strip(' \\'') for wordpair in wordpairs_list for word in wordpair]\n",
    "    words = set(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_embedding_dict(words):\n",
    "    word_embedding_dict = OrderedDict()\n",
    "    #Calculate embeddings\n",
    "    for word in words:\n",
    "        #Find the mfcc features of the acoustic representation of the word in the data\n",
    "        word_features = inputs[np.where(np.isin(labels,word_to_num[word]))]\n",
    "        \n",
    "        #Calculate embeddings for the feature\n",
    "        word_embedding = net.give_embeddings(torch.tensor(word_features, device = dev, dtype=torch.float),dev)\n",
    "        \n",
    "        #If the number of representation is more than one, take the average embedding\n",
    "        word_embedding_dict[word] = np.mean(word_embedding, axis = 0).reshape(1,-1)\n",
    "    \n",
    "    return word_embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embedding_distance(homophone_df,word_embedding_dict,metrics = ['cosine']):\n",
    "\n",
    "    word1_embeddings = None\n",
    "    word2_embeddings = None\n",
    "    \n",
    "    metric_distance_dict = {}\n",
    "    for metric in metrics:\n",
    "        metric_distance_dict[metric] = []\n",
    "        \n",
    "    for row in homophone_df.itertuples():\n",
    "        word1, word2 = map(lambda x: x.strip(' \\''),row.word_pairs.strip('()').split(','))\n",
    "        \n",
    "        for metric in metrics:\n",
    "            metric_distance_dict[metric].append(paired_distances(word_embedding_dict[word1],word_embedding_dict[word2], metric = metric)[0])\n",
    "        \n",
    "        \n",
    "        #if word1_embeddings is None and word2_embeddings is None:\n",
    "        #    word1_embeddings = word_embedding_dict[word1]\n",
    "        #    word2_embeddings = word_embedding_dict[word2]\n",
    "        #else:\n",
    "        #    word1_embeddings = np.vstack((word1_embeddings, word_embedding_dict[word1]))\n",
    "        #    word2_embeddings = np.vstack((word2_embeddings, word_embedding_dict[word2]))\n",
    "            \n",
    "        \n",
    "\n",
    "    #Calculate the distance\n",
    "    #print(word1_embeddings.shape)\n",
    "    for metric in metrics:\n",
    "        #metric_distance = paired_distances(word1_embeddings,word2_embeddings, metric = metric)\n",
    "        homophone_df.insert(len(homophone_df.columns),\"%s_distance\"%(metric), metric_distance_dict[metric], True)\n",
    "    \n",
    "    return homophone_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_nearest_neighbours_on_embeddings(word_embedding_dict, n_neighbours = 10, metric = 'cosine', split = False):\n",
    "    \n",
    "    embeddings = None\n",
    "    \n",
    "    embeddings = np.stack(list(word_embedding_dict.values())).squeeze()\n",
    "    \n",
    "    print('Calculating Nearest Neighbours')\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbours, algorithm='brute',metric = metric, n_jobs = 4).fit(embeddings)\n",
    "    distances,indices = nbrs.kneighbors(embeddings)\n",
    "    \n",
    "    columns = [\"word\",\"neighbours\"]\n",
    "    #nearest_neighbours_df = pd.DataFrame(columns = columns)\n",
    "    \n",
    "    words = list(word_embedding_dict.keys())\n",
    "    print('num of words %d'%(len(words)))\n",
    "    \n",
    "    \n",
    "    nearest_neighbours_df = pd.DataFrame(columns = columns)\n",
    "    \n",
    "    for i,word in enumerate(word_embedding_dict.keys()):\n",
    "        \n",
    "        neighbours = ','.join([words[indices[i,j]] for j in range(indices.shape[1]) if words[indices[i,j]]!= word])\n",
    "        #print(neighbours)\n",
    "        row = pd.DataFrame(np.array([[word],[neighbours]]).T, columns = columns)\n",
    "        nearest_neighbours_df = nearest_neighbours_df.append(row)\n",
    "        \n",
    "    \n",
    "    #pd.concat([pd.DataFrame(np.array([[word],[','.join([words[indices[i,j]] for j in range(indices.shape[1]) if words[indices[i,j]]!=word ])]]).T, columns = columns) for i,word in enumerate(word_embedding_dict.keys())])\n",
    "    \n",
    "    if split:\n",
    "        neighbour_col_names = [\"neighbour_%d\"%(i) for i in range(n_neighbours)]\n",
    "        nearest_neighbours_df[neighbour_col_names] = nearest_neighbours_df.neighbours.str.split(',', expand = True )\n",
    "        nearest_neighbours_df.drop(columns = [\"neighbours\"],inplace = True)\n",
    "    \n",
    "    \n",
    "    #Reset index\n",
    "    nearest_neighbours_df = nearest_neighbours_df.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return nearest_neighbours_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_dict = generate_word_embedding_dict(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_dict = generate_word_embedding_dict(c.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Data/word_embedding_dict.npy\",word_embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_nearest_neighbours = give_nearest_neighbours_on_embeddings(word_embedding_dict, 10,'cosine', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_nearest_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_nearest_neighbours.to_csv('Data/em_nearest_neighbours.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbours_df[nearest_neighbours_df[\"word\"]==\"cameras\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = calculate_embedding_distance(wordpairs_df,word_embedding_dict,metrics = ['cosine', 'euclidean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.scatterplot(\n",
    "    x=\"phonetic_edit_distance\", y=\"%s_distance\"%(metrics[0]),\n",
    "    #hue=\"Word\",\n",
    "    data=df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.5)\n",
    "g.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.scatterplot(\n",
    "    x=\"phonetic_edit_distance\", y=\"%s_distance\"%(metrics[1]),\n",
    "    #hue=\"Word\",\n",
    "    data=df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.5)\n",
    "g.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('phonetic_edit_distance', as_index = False).agg(['mean', 'count', 'std'], index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.scatterplot(\n",
    "    x=\"phonetic_edit_distance\", y=\"%s_distance\"%(metrics[0]),\n",
    "    #hue=\"Word\",\n",
    "    data=df.groupby('phonetic_edit_distance', as_index = False).mean(),\n",
    "    legend=\"full\",\n",
    "    alpha=0.5)\n",
    "plt.ylabel('average cosine distance')\n",
    "#g.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.scatterplot(\n",
    "    x=\"phonetic_edit_distance\", y=\"%s_distance\"%(metrics[1]),\n",
    "    #hue=\"Word\",\n",
    "    data=df.groupby('phonetic_edit_distance', as_index = False).mean(),\n",
    "    legend=\"full\",\n",
    "    alpha=0.5)\n",
    "plt.ylabel('average euclidean distance')\n",
    "#g.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the homophones_df and split it word pairs into indiviudal columns\n",
    "homophones = pd.read_csv('Data/homophones.txt')\n",
    "column_names = ['word_1','word_2']\n",
    "homophones[column_names] = homophones.word_pairs.str.strip('()').str.split(',', expand = True)\n",
    "homophones[\"word_1\"] = homophones.word_1.str.strip(' \\'\\'')\n",
    "homophones[\"word_2\"] = homophones.word_2.str.strip(' \\'')\n",
    "del homophones[\"word_pairs\"]\n",
    "cols = list(homophones)\n",
    "# move the column to head of list using index, pop and insert\n",
    "cols.insert(0, cols.pop(cols.index('word_2')))\n",
    "cols.insert(0, cols.pop(cols.index('word_1')))\n",
    "homophones = homophones.loc[:, cols]\n",
    "homophones.to_csv('Data/homophones_expanded.txt', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start of Nearest Neighbour Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophones = pd.read_csv('Data/wordpairs_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>orthographic_edit_distance</th>\n",
       "      <th>raw_phonetic_edit_distance</th>\n",
       "      <th>filtered_phonetic_edit_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>important</td>\n",
       "      <td>probability</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metre</td>\n",
       "      <td>proper</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>buying</td>\n",
       "      <td>class</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mention</td>\n",
       "      <td>question</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>functions</td>\n",
       "      <td>promoting</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70120</th>\n",
       "      <td>ready</td>\n",
       "      <td>series</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70121</th>\n",
       "      <td>please</td>\n",
       "      <td>tongue</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70122</th>\n",
       "      <td>choice</td>\n",
       "      <td>search</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70123</th>\n",
       "      <td>displayed</td>\n",
       "      <td>separate</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70124</th>\n",
       "      <td>looked</td>\n",
       "      <td>speaks</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70125 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word_1       word_2  orthographic_edit_distance  \\\n",
       "0      important  probability                          10   \n",
       "1          metre       proper                           5   \n",
       "2         buying        class                           6   \n",
       "3        mention     question                           3   \n",
       "4      functions    promoting                           7   \n",
       "...          ...          ...                         ...   \n",
       "70120      ready       series                           5   \n",
       "70121     please       tongue                           5   \n",
       "70122     choice       search                           5   \n",
       "70123  displayed     separate                           7   \n",
       "70124     looked       speaks                           6   \n",
       "\n",
       "       raw_phonetic_edit_distance  filtered_phonetic_edit_distance  \n",
       "0                              10                               10  \n",
       "1                               4                                4  \n",
       "2                               4                                4  \n",
       "3                               4                                4  \n",
       "4                               8                                8  \n",
       "...                           ...                              ...  \n",
       "70120                           4                                4  \n",
       "70121                           4                                4  \n",
       "70122                           3                                3  \n",
       "70123                           6                                5  \n",
       "70124                           4                                4  \n",
       "\n",
       "[70125 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homophones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n"
     ]
    }
   ],
   "source": [
    "#Get list of words\n",
    "words = set(homophones[\"word_1\"].to_list()).union(set(homophones[\"word_2\"].to_list()))\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_columns(query):\n",
    "    #Swap columns\n",
    "    cols = list(query)\n",
    "    cols.insert(0, cols.pop(cols.index('word_2')))\n",
    "    query = query.loc[:, cols]\n",
    "    #Change column names\n",
    "    query.columns = [\"word_1\",\"word_2\",\"orthographic_edit_distance\",\"raw_phonetic_edit_distance\",\"filtered_phonetic_edit_distance\"]\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_phoneme_dict(words, phoney):\n",
    "    '''Given a list of words generate a dictionary with their phonetic expansions'''\n",
    "    word_phoneme_dict = {}\n",
    "    for word in words:\n",
    "        word_phoneme_dict[word] = phoney.phonize(word)\n",
    "    \n",
    "    return word_phoneme_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a phonetic expansion dict\n",
    "phoney = BigPhoney()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_phoneme_dict = generate_word_phoneme_dict(words,phoney)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'another': 'AH0 N AH1 DH ER0',\n",
       " 'interpretation': 'IH2 N T ER2 P R IH0 T EY1 SH AH0 N',\n",
       " 'instructions': 'IH2 N S T R AH1 K SH AH0 N Z',\n",
       " 'corpus': 'K AO1 R P AH0 S',\n",
       " 'preservatives': 'P R AH0 Z ER1 V AH0 T IH0 V Z',\n",
       " 'leadership': 'L IY1 D ER0 SH IH2 P',\n",
       " 'heavily': 'HH EH1 V AH0 L IY0',\n",
       " 'expensive': 'IH0 K S P EH1 N S IH0 V',\n",
       " 'definition': 'D EH2 F AH0 N IH1 SH AH0 N',\n",
       " 'probability': 'P R AA2 B AH0 B IH1 L AH0 T IY2',\n",
       " 'across': 'AH0 K R AO1 S',\n",
       " 'really': 'R IH1 L IY0',\n",
       " 'language': 'L AE1 NG G W AH0 JH',\n",
       " 'connect': 'K AH0 N EH1 K T',\n",
       " 'point': 'P OY1 N T',\n",
       " 'incorporate': 'IH2 N K AO1 R P ER0 EY2 T',\n",
       " 'beeper': 'B IY1 P ER0',\n",
       " 'sound': 'S AW1 N D',\n",
       " 'guess': 'G EH1 S',\n",
       " 'class': 'K L AE1 S',\n",
       " 'working': 'W ER1 K IH0 NG',\n",
       " 'thursday': 'TH ER1 Z D EY2',\n",
       " 'ionising': 'AY1 AH0 N AY2 Z IH0 NG',\n",
       " 'whole': 'HH OW1 L',\n",
       " 'achieve': 'AH0 CH IY1 V',\n",
       " 'shifted': 'SH IH1 F T AH0 D',\n",
       " 'thatd': 'TH AE1 T',\n",
       " 'whats': 'W AH0 T S',\n",
       " 'interface': 'IH1 N T ER0 F EY2 S',\n",
       " 'exchange': 'IH0 K S CH EY1 N JH',\n",
       " 'display': 'D IH0 S P L EY1',\n",
       " 'things': 'TH IH1 NG Z',\n",
       " 'places': 'P L EY1 S AH0 Z',\n",
       " 'sheet': 'SH IY1 T',\n",
       " 'should': 'SH UH1 D',\n",
       " 'scroll': 'S K R OW1 L',\n",
       " 'purposes': 'P ER1 P AH0 S AH0 Z',\n",
       " 'becau': 'B IH0 K OW1',\n",
       " 'pronunciation': 'P R OW0 N AH2 N S IY0 EY1 SH AH0 N',\n",
       " 'david': 'D EY1 V IH0 D',\n",
       " 'single': 'S IH1 NG G AH0 L',\n",
       " 'binary': 'B AY1 N AH0 R IY2',\n",
       " 'doing': 'D UW1 IH0 NG',\n",
       " 'through': 'TH R UW1',\n",
       " 'stuff': 'S T AH1 F',\n",
       " 'kinda': 'K IH1 N D AH0',\n",
       " 'identified': 'AY0 D EH1 N T AH0 F AY2 D',\n",
       " 'coffee': 'K AA1 F IY0',\n",
       " 'storage': 'S T AO1 R AH0 JH',\n",
       " 'pages': 'P EY1 JH AH0 Z',\n",
       " 'remit': 'R IY0 M IH1 T',\n",
       " 'version': 'V ER1 ZH AH0 N',\n",
       " 'headsets': 'HH EH1 D S EH2 T S',\n",
       " 'power': 'P AW1 ER0',\n",
       " 'informatics': 'IH2 N F AO2 R M AE1 T IH0 K S',\n",
       " 'especially': 'AH0 S P EH1 SH L IY0',\n",
       " 'thirty': 'TH ER1 D IY2',\n",
       " 'suppose': 'S AH0 P OW1 Z',\n",
       " 'touch': 'T AH1 CH',\n",
       " 'terms': 'T ER1 M Z',\n",
       " 'designs': 'D IH0 Z AY1 N Z',\n",
       " 'options': 'AA1 P SH AH0 N Z',\n",
       " 'other': 'AH1 DH ER0',\n",
       " 'televisions': 'T EH1 L AH0 V IH2 ZH AH0 N Z',\n",
       " 'series': 'S IH1 R IY0 Z',\n",
       " 'bring': 'B R IH1 NG',\n",
       " 'injury': 'IH1 N JH ER0 IY0',\n",
       " 'trends': 'T R EH1 N D Z',\n",
       " 'videoplus': 'V IH1 D IY0 OW0 P L AH0 S',\n",
       " 'deadline': 'D EH1 D L AY2 N',\n",
       " 'edible': 'EH1 D AH0 B AH0 L',\n",
       " 'little': 'L IH1 T AH0 L',\n",
       " 'since': 'S IH1 N S',\n",
       " 'careful': 'K EH1 R F AH0 L',\n",
       " 'seven': 'S EH1 V AH0 N',\n",
       " 'nothing': 'N AH1 TH IH0 NG',\n",
       " 'besides': 'B IH0 S AY1 D Z',\n",
       " 'system': 'S IH1 S T AH0 M',\n",
       " 'ready': 'R EH1 D IY0',\n",
       " 'final': 'F AY1 N AH0 L',\n",
       " 'night': 'N AY1 T',\n",
       " 'shortcuts': 'SH AO1 R T K AH2 T S',\n",
       " 'product': 'P R AA1 D AH0 K T',\n",
       " 'table': 'T EY1 B AH0 L',\n",
       " 'typically': 'T IH1 P IH0 K L IY0',\n",
       " 'strain': 'S T R EY1 N',\n",
       " 'could': 'K UH1 D',\n",
       " 'travel': 'T R AE1 V AH0 L',\n",
       " 'connection': 'K AH0 N EH1 K SH AH0 N',\n",
       " 'uhhuh': 'UW1 HH UW0',\n",
       " 'reached': 'R IY1 CH T',\n",
       " 'manager': 'M AE1 N AH0 JH ER0',\n",
       " 'looked': 'L UH1 K T',\n",
       " 'controls': 'K AH0 N T R OW1 L Z',\n",
       " 'report': 'R IY0 P AO1 R T',\n",
       " 'buying': 'B AY1 IH0 NG',\n",
       " 'collect': 'K AH0 L EH1 K T',\n",
       " 'controller': 'K AH0 N T R OW1 L ER0',\n",
       " 'battery': 'B AE1 T ER0 IY0',\n",
       " 'meeting': 'M IY1 T IH0 NG',\n",
       " 'advantage': 'AE0 D V AE1 N T IH0 JH',\n",
       " 'explains': 'IH0 K S P L EY1 N Z',\n",
       " 'conjunctural': 'K AH0 N JH AH1 NG K CH ER0 AH0 L',\n",
       " 'repetitive': 'R IH0 P EH1 T IH0 T IH0 V',\n",
       " 'trying': 'T R AY1 IH0 NG',\n",
       " 'enough': 'IH0 N AH1 F',\n",
       " 'maintain': 'M EY0 N T EY1 N',\n",
       " 'pistol': 'P IH1 S T AH0 L',\n",
       " 'ourselves': 'AW0 ER0 S EH1 L V Z',\n",
       " 'option': 'AA1 P SH AH0 N',\n",
       " 'channels': 'CH AE1 N AH0 L Z',\n",
       " 'design': 'D IH0 Z AY1 N',\n",
       " 'receive': 'R AH0 S IY1 V',\n",
       " 'havent': 'HH AE1 V AH0 N T',\n",
       " 'thank': 'TH AE1 NG K',\n",
       " 'mister': 'M IH1 S T ER0',\n",
       " 'kinetic': 'K AH0 N EH1 T IH0 K',\n",
       " 'sense': 'S EH1 N S',\n",
       " 'shops': 'SH AA1 P S',\n",
       " 'radio': 'R EY1 D IY0 OW2',\n",
       " 'because': 'B IH0 K AO1 Z',\n",
       " 'definite': 'D EH1 F AH0 N AH0 T',\n",
       " 'anything': 'EH1 N IY0 TH IH2 NG',\n",
       " 'diffic': 'D IH1 F IH0 K',\n",
       " 'around': 'ER0 AW1 N D',\n",
       " 'buttons': 'B AH1 T AH0 N Z',\n",
       " 'given': 'G IH1 V AH0 N',\n",
       " 'match': 'M AE1 CH',\n",
       " 'plates': 'P L EY1 T S',\n",
       " 'colours': 'K AH1 L ER0 Z',\n",
       " 'short': 'SH AO1 R T',\n",
       " 'celebration': 'S EH2 L AH0 B R EY1 SH AH0 N',\n",
       " 'titaniumcoloured': 'T IH2 T AH0 N Y UW1 M K AH0 L ER0 D',\n",
       " 'percent': 'P ER0 S EH1 N T',\n",
       " 'these': 'DH IY1 Z',\n",
       " 'speaks': 'S P IY1 K S',\n",
       " 'rounded': 'R AW1 N D AH0 D',\n",
       " 'reminder': 'R IY0 M AY1 N D ER0',\n",
       " 'minutes': 'M IH1 N AH0 T S',\n",
       " 'master': 'M AE1 S T ER0',\n",
       " 'information': 'IH2 N F AO2 R M EY1 SH AH0 N',\n",
       " 'discourse': 'D IH1 S K AO0 R S',\n",
       " 'actually': 'AE1 K CH UW2 AH0 L IY0',\n",
       " 'although': 'AO2 L DH OW1',\n",
       " 'remote': 'R IH0 M OW1 T',\n",
       " 'question': 'K W EH1 S CH AH0 N',\n",
       " 'laughter': 'L AE1 F T ER0',\n",
       " 'people': 'P IY1 P AH0 L',\n",
       " 'sorta': 'S AO1 R T AH0',\n",
       " 'again': 'AH0 G EH1 N',\n",
       " 'please': 'P L IY1 Z',\n",
       " 'studies': 'S T AH1 D IY0 Z',\n",
       " 'looking': 'L UH1 K IH0 NG',\n",
       " 'shall': 'SH AE1 L',\n",
       " 'familiarity': 'F AH0 M IH2 L Y EH1 R AH0 T IY0',\n",
       " 'first': 'F ER1 S T',\n",
       " 'forth': 'F AO1 R TH',\n",
       " 'interesting': 'IH1 N T AH0 R EH2 S T IH0 NG',\n",
       " 'reports': 'R IH0 P AO1 R T S',\n",
       " 'corporate': 'K AO1 R P ER0 AH0 T',\n",
       " 'jordan': 'JH AO1 R D AH0 N',\n",
       " 'incremental': 'IH2 N K R AH0 M EH1 N T AH0 L',\n",
       " 'circuits': 'S ER1 K AH0 T S',\n",
       " 'theme': 'TH IY1 M',\n",
       " 'range': 'R EY1 N JH',\n",
       " 'keywords': 'K IY1 W ER2 D Z',\n",
       " 'zapping': 'Z AE1 P IH0 NG',\n",
       " 'their': 'DH EH1 R',\n",
       " 'search': 'S ER1 CH',\n",
       " 'creativity': 'K R IY2 EY0 T IH1 V AH0 T IY0',\n",
       " 'numbe': 'N AH1 M B',\n",
       " 'biased': 'B AY1 AH0 S T',\n",
       " 'those': 'DH OW1 Z',\n",
       " 'documents': 'D AA1 K Y AH0 M AH0 N T S',\n",
       " 'basically': 'B EY1 S IH0 K L IY0',\n",
       " 'eighties': 'EY1 T IY0 Z',\n",
       " 'still': 'S T IH1 L',\n",
       " 'quite': 'K W AY1 T',\n",
       " 'something': 'S AH1 M TH IH0 NG',\n",
       " 'wouldnt': 'W UH1 D AH0 N T',\n",
       " 'refers': 'R AH0 F ER1 Z',\n",
       " 'delayed': 'D IH0 L EY1 D',\n",
       " 'happy': 'HH AE1 P IY0',\n",
       " 'going': 'G OW1 IH0 NG',\n",
       " 'choice': 'CH OY1 S',\n",
       " 'multiselect': 'M AH1 L T IY0 S AH0 L EH2 K T',\n",
       " 'changing': 'CH EY1 N JH IH0 NG',\n",
       " 'spongy': 'S P AH1 N JH IY0',\n",
       " 'mustnt': 'M AH1 S T AH0 N T',\n",
       " 'numbers': 'N AH1 M B ER0 Z',\n",
       " 'already': 'AO0 L R EH1 D IY0',\n",
       " 'probably': 'P R AA1 B AH0 B L IY2',\n",
       " 'portable': 'P AO1 R T AH0 B AH0 L',\n",
       " 'device': 'D IH0 V AY1 S',\n",
       " 'theoretically': 'TH IY2 ER0 EH1 T IH0 K AH0 L IY0',\n",
       " 'mention': 'M EH1 N SH AH0 N',\n",
       " 'gonna': 'G AA1 N AH0',\n",
       " 'happens': 'HH AE1 P AH0 N Z',\n",
       " 'exactly': 'IH0 G Z AE1 K T L IY0',\n",
       " 'sorry': 'S AA1 R IY0',\n",
       " 'right': 'R AY1 T',\n",
       " 'switch': 'S W IH1 CH',\n",
       " 'digital': 'D IH1 JH AH0 T AH0 L',\n",
       " 'control': 'K AH0 N T R OW1 L',\n",
       " 'electronics': 'IH2 L EH2 K T R AA1 N IH0 K S',\n",
       " 'regular': 'R EH1 G Y AH0 L ER0',\n",
       " 'shapes': 'SH EY1 P S',\n",
       " 'fixations': 'F IH0 K S EY1 SH AH0 N Z',\n",
       " 'maybe': 'M EY1 B IY0',\n",
       " 'means': 'M IY1 N Z',\n",
       " 'thing': 'TH IH1 NG',\n",
       " 'requirements': 'R IH0 K W AY1 R M AH0 N T S',\n",
       " 'discussion': 'D IH0 S K AH1 SH AH0 N',\n",
       " 'theres': 'DH EH1 R Z',\n",
       " 'before': 'B IH0 F AO1 R',\n",
       " 'guide': 'G AY1 D',\n",
       " 'issue': 'IH1 SH UW0',\n",
       " 'proper': 'P R AA1 P ER0',\n",
       " 'therefore': 'DH EH1 R F AO2 R',\n",
       " 'which': 'W IH1 CH',\n",
       " 'thought': 'TH AO1 T',\n",
       " 'stick': 'S T IH1 K',\n",
       " 'mentioned': 'M EH1 N SH AH0 N D',\n",
       " 'though': 'DH OW1',\n",
       " 'stream': 'S T R IY1 M',\n",
       " 'pretty': 'P R IH1 T IY0',\n",
       " 'plastic': 'P L AE1 S T IH0 K',\n",
       " 'think': 'TH IH1 NG K',\n",
       " 'parts': 'P AA1 R T S',\n",
       " 'general': 'JH EH1 N ER0 AH0 L',\n",
       " 'material': 'M AH0 T IH1 R IY0 AH0 L',\n",
       " 'origins': 'AO1 R AH0 JH IH0 N Z',\n",
       " 'flexible': 'F L EH1 K S AH0 B AH0 L',\n",
       " 'matter': 'M AE1 T ER0',\n",
       " 'cheap': 'CH IY1 P',\n",
       " 'continua': 'K AH0 N T IH1 N Y UW0 AH0',\n",
       " 'problem': 'P R AA1 B L AH0 M',\n",
       " 'thats': 'TH AE1 T S',\n",
       " 'different': 'D IH1 F ER0 AH0 N T',\n",
       " 'models': 'M AA1 D AH0 L Z',\n",
       " 'mmhmm': 'M AH0 M EH1 M',\n",
       " 'increasingly': 'IH2 N K R IY1 S IH0 NG G L IY0',\n",
       " 'cover': 'K AH1 V ER0',\n",
       " 'forever': 'F ER0 EH1 V ER0',\n",
       " 'remotes': 'R IY0 M OW1 T S',\n",
       " 'greater': 'G R EY1 T ER0',\n",
       " 'adding': 'AE1 D IH0 NG',\n",
       " 'thumb': 'TH AH1 M',\n",
       " 'decided': 'D IH2 S AY1 D IH0 D',\n",
       " 'child': 'CH AY1 L D',\n",
       " 'twenty': 'T W EH1 N T IY0',\n",
       " 'clearly': 'K L IH1 R L IY0',\n",
       " 'teach': 'T IY1 CH',\n",
       " 'everything': 'EH1 V R IY0 TH IH2 NG',\n",
       " 'analysis': 'AE0 N AE1 L IH0 S IH0 S',\n",
       " 'start': 'S T AA1 R T',\n",
       " 'important': 'IH2 M P AO1 R T AH0 N T',\n",
       " 'optional': 'AA1 P SH AH0 N AH0 L',\n",
       " 'number': 'N AH1 M B ER0',\n",
       " 'existing': 'IH0 G Z IH1 S T IH0 NG',\n",
       " 'curve': 'K ER1 V',\n",
       " 'feeling': 'F IY1 L IH0 NG',\n",
       " 'excel': 'IH0 K S EH1 L',\n",
       " 'bluetooth': 'B L UW1 T UW2 TH',\n",
       " 'change': 'CH EY1 N JH',\n",
       " 'doesnt': 'D OW1 S AH0 N T',\n",
       " 'resemblance': 'R IH0 Z EH1 M B L AH0 N S',\n",
       " 'tongue': 'T AH1 NG',\n",
       " 'project': 'P R AA1 JH EH0 K T',\n",
       " 'greyed': 'G R EY1 D',\n",
       " 'square': 'S K W EH1 R',\n",
       " 'programme': 'P R OW1 G R AE2 M',\n",
       " 'mirror': 'M IH1 R ER0',\n",
       " 'prominent': 'P R AA1 M AH0 N AH0 N T',\n",
       " 'promoting': 'P R AH0 M OW1 T IH0 NG',\n",
       " 'definitely': 'D EH1 F AH0 N AH0 T L IY0',\n",
       " 'twelve': 'T W EH1 L V',\n",
       " 'close': 'K L OW1 S',\n",
       " 'anyway': 'EH1 N IY0 W EY2',\n",
       " 'typic': 'T IH1 P IH0 K',\n",
       " 'fronts': 'F R AH1 N T S',\n",
       " 'saying': 'S EY1 IH0 NG',\n",
       " 'might': 'M AY1 T',\n",
       " 'abstract': 'AE0 B S T R AE1 K T',\n",
       " 'holding': 'HH OW1 L D IH0 NG',\n",
       " 'wanna': 'W AA1 N AH0',\n",
       " 'useless': 'Y UW1 S L AH0 S',\n",
       " 'brown': 'B R AW1 N',\n",
       " 'separate': 'S EH1 P ER0 EY2 T',\n",
       " 'choose': 'CH UW1 Z',\n",
       " 'notes': 'N OW1 T S',\n",
       " 'drawings': 'D R AO1 IH0 NG Z',\n",
       " 'telescope': 'T EH1 L AH0 S K OW2 P',\n",
       " 'instrument': 'IH1 N S T R AH0 M AH0 N T',\n",
       " 'button': 'B AH1 T AH0 N',\n",
       " 'quality': 'K W AA1 L AH0 T IY0',\n",
       " 'advanced': 'AH0 D V AE1 N S T',\n",
       " 'playdoh': 'P L EY1 D OW0',\n",
       " 'wheat': 'W IY1 T',\n",
       " 'website': 'W EH1 B S AY2 T',\n",
       " 'autumn': 'AO1 T AH0 M',\n",
       " 'gadget': 'G AE1 JH AH0 T',\n",
       " 'metre': 'M IY1 T ER0',\n",
       " 'occurs': 'AH0 K ER1 Z',\n",
       " 'latex': 'L EY1 T EH2 K S',\n",
       " 'specific': 'S P AH0 S IH1 F IH0 K',\n",
       " 'yellow': 'Y EH1 L OW0',\n",
       " 'drawing': 'D R AO1 IH0 NG',\n",
       " 'watching': 'W AA1 CH IH0 NG',\n",
       " 'email': 'IY0 M EY1 L',\n",
       " 'fancy': 'F AE1 N S IY0',\n",
       " 'possible': 'P AA1 S AH0 B AH0 L',\n",
       " 'required': 'R IY0 K W AY1 ER0 D',\n",
       " 'quick': 'K W IH1 K',\n",
       " 'lights': 'L AY1 T S',\n",
       " 'thinking': 'TH IH1 NG K IH0 NG',\n",
       " 'functions': 'F AH1 NG K SH AH0 N Z',\n",
       " 'fourth': 'F AO1 R TH',\n",
       " 'navigate': 'N AE1 V AH0 G EY2 T',\n",
       " 'chunking': 'CH AH1 NG K IH0 NG',\n",
       " 'somewhere': 'S AH1 M W EH2 R',\n",
       " 'outsmart': 'AW1 T S M AA2 R T',\n",
       " 'pushbuttons': 'P UH1 SH B AH2 T AH0 N Z',\n",
       " 'annoying': 'AH0 N OY1 IH0 NG',\n",
       " 'calculates': 'K AE1 L K Y AH0 L EY2 T S',\n",
       " 'liking': 'L AY1 K IH0 NG',\n",
       " 'accessories': 'AE0 K S EH1 S ER0 IY0 Z',\n",
       " 'trick': 'T R IH1 K',\n",
       " 'thanks': 'TH AE1 NG K S',\n",
       " 'basic': 'B EY1 S IH0 K',\n",
       " 'theyre': 'DH EH1 R',\n",
       " 'above': 'AH0 B AH1 V',\n",
       " 'submission': 'S AH0 B M IH1 SH AH0 N',\n",
       " 'firewire': 'F AY1 R W AY2 R',\n",
       " 'paper': 'P EY1 P ER0',\n",
       " 'process': 'P R AA1 S EH2 S',\n",
       " 'better': 'B EH1 T ER0',\n",
       " 'smoke': 'S M OW1 K',\n",
       " 'lunch': 'L AH1 N CH',\n",
       " 'daniel': 'D AE1 N Y AH0 L',\n",
       " 'grippy': 'G R IH1 P IY0',\n",
       " 'correspond': 'K AO2 R AH0 S P AA1 N D',\n",
       " 'scores': 'S K AO1 R Z',\n",
       " 'checking': 'CH EH1 K IH0 NG',\n",
       " 'exists': 'IH0 G Z IH1 S T S',\n",
       " 'cross': 'K R AO1 S',\n",
       " 'station': 'S T EY1 SH AH0 N',\n",
       " 'fifty': 'F IH1 F T IY0',\n",
       " 'enumerated': 'IH0 N UW1 M ER0 EY2 T IH0 D',\n",
       " 'alright': 'AO2 L R AY1 T',\n",
       " 'analyse': 'AE1 N AH0 L AY2 Z',\n",
       " 'cutting': 'K AH1 T IH0 NG',\n",
       " 'either': 'IY1 DH ER0',\n",
       " 'together': 'T AH0 G EH1 DH ER0',\n",
       " 'meetings': 'M IY1 T IH0 NG Z',\n",
       " 'banana': 'B AH0 N AE1 N AH0',\n",
       " 'discuss': 'D IH0 S K AH1 S',\n",
       " 'displayed': 'D IH0 S P L EY1 D',\n",
       " 'channel': 'CH AE1 N AH0 L',\n",
       " 'whistle': 'W IH1 S AH0 L',\n",
       " 'order': 'AO1 R D ER0',\n",
       " 'light': 'L AY1 T',\n",
       " 'screen': 'S K R IY1 N',\n",
       " 'remember': 'R IH0 M EH1 M B ER0',\n",
       " 'clear': 'K L IH1 R',\n",
       " 'there': 'DH EH1 R',\n",
       " 'seems': 'S IY1 M Z',\n",
       " 'browse': 'B R AW1 Z',\n",
       " 'about': 'AH0 B AW1 T',\n",
       " 'shape': 'SH EY1 P',\n",
       " 'research': 'R IY0 S ER1 CH',\n",
       " 'possibly': 'P AA1 S AH0 B L IY0',\n",
       " 'standards': 'S T AE1 N D ER0 D Z',\n",
       " 'remarkably': 'R IH0 M AA1 R K AH0 B L IY0',\n",
       " 'adopt': 'AH0 D AA1 P T'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_phoneme_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_score(ser):\n",
    "    return 10 - min(10,ser/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similarity based NNs\n",
    "sim_nn_dict = {}\n",
    "sim_nn_dict[\"word\"] = []\n",
    "sim_nn_dict[\"orthographic\"] = []\n",
    "sim_nn_dict[\"raw_phonetic\"] = []\n",
    "sim_nn_dict[\"filtered_phonetic\"] = []\n",
    "\n",
    "\n",
    "#Edit Distance based NNs\n",
    "edit_nn_dict = {}\n",
    "edit_nn_dict[\"word\"] = []\n",
    "edit_nn_dict[\"orthographic\"] = []\n",
    "edit_nn_dict[\"raw_phonetic\"] = []\n",
    "edit_nn_dict[\"filtered_phonetic\"] = []\n",
    "\n",
    "\n",
    "test_words = [\"seven\",\"sheet\"]\n",
    "for word in test_words:\n",
    "\n",
    "    query = pd.concat([homophones.query(\"word_1 == '%s'\"%(word)),swap_columns(homophones.query(\"word_2 == '%s'\"%(word)))])\n",
    "\n",
    "    query[\"orthographic_sim\"] = query.apply(lambda row: sim_score(100*row[\"orthographic_edit_distance\"]/len(row[\"word_1\"])), axis = 1)\n",
    "    query[\"raw_phonetic_sim\"] = query.apply(lambda row: sim_score(100*row[\"raw_phonetic_edit_distance\"]/len(word_phoneme_dict[row[\"word_1\"]])), axis = 1)\n",
    "    query[\"filtered_phonetic_sim\"] = query.apply(lambda row: sim_score(100*row[\"filtered_phonetic_edit_distance\"]/len(word_phoneme_dict[row[\"word_1\"]])), axis = 1)\n",
    "\n",
    "    sim_orthographic_nn = tuple(query.sort_values( \"orthographic_sim\", ascending =False).iloc[:10][\"word_2\"].to_list())\n",
    "    sim_raw_phonetic_nn = tuple(query.sort_values( \"raw_phonetic_sim\", ascending =False).iloc[:10][\"word_2\"].to_list())\n",
    "    sim_filtered_phonetic_nn = tuple(query.sort_values( \"filtered_phonetic_sim\", ascending =False).iloc[:10][\"word_2\"].to_list())\n",
    "\n",
    "\n",
    "    edit_orthographic_nn = tuple(query.sort_values( \"orthographic_edit_distance\", ascending = True).iloc[:10][\"word_2\"].to_list())\n",
    "    edit_raw_phonetic_nn = tuple(query.sort_values( \"raw_phonetic_edit_distance\", ascending = True).iloc[:10][\"word_2\"].to_list())\n",
    "    edit_filtered_phonetic_nn = tuple(query.sort_values( \"filtered_phonetic_edit_distance\", ascending = True).iloc[:10][\"word_2\"].to_list())\n",
    "\n",
    "    sim_nn_dict[\"word\"].append(word)\n",
    "    sim_nn_dict[\"orthographic\"].append(sim_orthographic_nn)\n",
    "    sim_nn_dict[\"raw_phonetic\"].append(sim_raw_phonetic_nn)\n",
    "    sim_nn_dict[\"filtered_phonetic\"].append(sim_filtered_phonetic_nn)\n",
    "\n",
    "\n",
    "    edit_nn_dict[\"word\"].append(word)\n",
    "    edit_nn_dict[\"orthographic\"].append(edit_orthographic_nn)\n",
    "    edit_nn_dict[\"raw_phonetic\"].append(edit_raw_phonetic_nn)\n",
    "    edit_nn_dict[\"filtered_phonetic\"].append(edit_filtered_phonetic_nn)\n",
    "\n",
    "    del query\n",
    "\n",
    "sim_nn_df = pd.DataFrame(sim_nn_dict)\n",
    "edit_nn_df = pd.DataFrame(edit_nn_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>orthographic</th>\n",
       "      <th>raw_phonetic</th>\n",
       "      <th>filtered_phonetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seven</td>\n",
       "      <td>(given, seems, sheet, cover, series, screen, h...</td>\n",
       "      <td>(given, screen, version, station, button, sens...</td>\n",
       "      <td>(given, station, heavily, strain, mention, hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sheet</td>\n",
       "      <td>(short, wheat, screen, theme, cheap, shall, th...</td>\n",
       "      <td>(wheat, right, shall, thought, reached, might,...</td>\n",
       "      <td>(wheat, shape, shall, thought, right, cheap, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word                                       orthographic  \\\n",
       "0  seven  (given, seems, sheet, cover, series, screen, h...   \n",
       "1  sheet  (short, wheat, screen, theme, cheap, shall, th...   \n",
       "\n",
       "                                        raw_phonetic  \\\n",
       "0  (given, screen, version, station, button, sens...   \n",
       "1  (wheat, right, shall, thought, reached, might,...   \n",
       "\n",
       "                                   filtered_phonetic  \n",
       "0  (given, station, heavily, strain, mention, hav...  \n",
       "1  (wheat, shape, shall, thought, right, cheap, s...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_nn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>orthographic</th>\n",
       "      <th>raw_phonetic</th>\n",
       "      <th>filtered_phonetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seven</td>\n",
       "      <td>(given, sheet, screen, cover, series, seems, h...</td>\n",
       "      <td>(given, screen, mention, heavily, station, opt...</td>\n",
       "      <td>(given, stuff, havent, heavily, button, screen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sheet</td>\n",
       "      <td>(short, wheat, cheap, shall, theme, their, sta...</td>\n",
       "      <td>(wheat, metre, thatd, reached, shape, thought,...</td>\n",
       "      <td>(wheat, shall, teach, might, metre, these, sho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word                                       orthographic  \\\n",
       "0  seven  (given, sheet, screen, cover, series, seems, h...   \n",
       "1  sheet  (short, wheat, cheap, shall, theme, their, sta...   \n",
       "\n",
       "                                        raw_phonetic  \\\n",
       "0  (given, screen, mention, heavily, station, opt...   \n",
       "1  (wheat, metre, thatd, reached, shape, thought,...   \n",
       "\n",
       "                                   filtered_phonetic  \n",
       "0  (given, stuff, havent, heavily, button, screen...  \n",
       "1  (wheat, shall, teach, might, metre, these, sho...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_nn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>orthographic_edit_distance</th>\n",
       "      <th>raw_phonetic_edit_distance</th>\n",
       "      <th>filtered_phonetic_edit_distance</th>\n",
       "      <th>orthographic_sim</th>\n",
       "      <th>raw_phonetic_sim</th>\n",
       "      <th>filtered_phonetic_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>sheet</td>\n",
       "      <td>things</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40939</th>\n",
       "      <td>sheet</td>\n",
       "      <td>definition</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40895</th>\n",
       "      <td>sheet</td>\n",
       "      <td>advanced</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40615</th>\n",
       "      <td>sheet</td>\n",
       "      <td>project</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40451</th>\n",
       "      <td>sheet</td>\n",
       "      <td>pushbuttons</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39987</th>\n",
       "      <td>sheet</td>\n",
       "      <td>corpus</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39667</th>\n",
       "      <td>sheet</td>\n",
       "      <td>decided</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39532</th>\n",
       "      <td>sheet</td>\n",
       "      <td>definitely</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39002</th>\n",
       "      <td>sheet</td>\n",
       "      <td>liking</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38951</th>\n",
       "      <td>sheet</td>\n",
       "      <td>please</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38859</th>\n",
       "      <td>sheet</td>\n",
       "      <td>chunking</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_1       word_2  orthographic_edit_distance  \\\n",
       "846    sheet       things                           5   \n",
       "40939  sheet   definition                           9   \n",
       "40895  sheet     advanced                           7   \n",
       "40615  sheet      project                           5   \n",
       "40451  sheet  pushbuttons                           8   \n",
       "39987  sheet       corpus                           6   \n",
       "39667  sheet      decided                           6   \n",
       "39532  sheet   definitely                           9   \n",
       "39002  sheet       liking                           6   \n",
       "38951  sheet       please                           5   \n",
       "38859  sheet     chunking                           7   \n",
       "\n",
       "       raw_phonetic_edit_distance  filtered_phonetic_edit_distance  \\\n",
       "846                             4                                4   \n",
       "40939                           8                                8   \n",
       "40895                           6                                6   \n",
       "40615                           6                                6   \n",
       "40451                           7                                7   \n",
       "39987                           6                                6   \n",
       "39667                           7                                7   \n",
       "39532                           8                                8   \n",
       "39002                           5                                5   \n",
       "38951                           3                                3   \n",
       "38859                           6                                6   \n",
       "\n",
       "       orthographic_sim  raw_phonetic_sim  filtered_phonetic_sim  \n",
       "846                 0.0              5.00                   5.00  \n",
       "40939               0.0              0.00                   0.00  \n",
       "40895               0.0              2.50                   2.50  \n",
       "40615               0.0              2.50                   2.50  \n",
       "40451               0.0              1.25                   1.25  \n",
       "39987               0.0              2.50                   2.50  \n",
       "39667               0.0              1.25                   1.25  \n",
       "39532               0.0              0.00                   0.00  \n",
       "39002               0.0              3.75                   3.75  \n",
       "38951               0.0              6.25                   6.25  \n",
       "38859               0.0              2.50                   2.50  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.sort_values(\"orthographic_sim\", ascending = True)[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seven\n",
      "('given', 'seems', 'sheet', 'cover', 'series', 'screen', 'havent', 'sense', 'smoke', 'remit')\n",
      "('given', 'screen', 'version', 'station', 'button', 'sense', 'heavily', 'option', 'havent', 'strain')\n",
      "('given', 'station', 'heavily', 'strain', 'mention', 'havent', 'screen', 'stuff', 'version', 'option')\n",
      "beeper\n",
      "('better', 'proper', 'paper', 'seems', 'shapes', 'series', 'cover', 'sense', 'seven', 'other')\n",
      "('better', 'metre', 'paper', 'either', 'cheap', 'theme', 'bring', 'battery', 'order', 'means')\n",
      "('paper', 'cheap', 'metre', 'either', 'better', 'sheet', 'proper', 'happy', 'wheat', 'battery')\n"
     ]
    }
   ],
   "source": [
    "for i,word in enumerate(test_words):\n",
    "    print(word)\n",
    "    print(nn_df.iloc[i][\"orthographic\"])\n",
    "    print(nn_df.iloc[i][\"raw_phonetic\"])\n",
    "    print(nn_df.iloc[i][\"filtered_phonetic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>orthographic_edit_distance</th>\n",
       "      <th>phonetic_edit_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amusement</td>\n",
       "      <td>discoveries</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avril</td>\n",
       "      <td>effect</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>biomorphic</td>\n",
       "      <td>serialize</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meeting</td>\n",
       "      <td>trendiness</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>formatting</td>\n",
       "      <td>hierarch</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49735346</th>\n",
       "      <td>alastair</td>\n",
       "      <td>autumn</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49735347</th>\n",
       "      <td>articulation</td>\n",
       "      <td>definite</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49735348</th>\n",
       "      <td>suppression</td>\n",
       "      <td>surprise</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49735349</th>\n",
       "      <td>keyword</td>\n",
       "      <td>realising</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49735350</th>\n",
       "      <td>similarit</td>\n",
       "      <td>widens</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49735351 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word_1       word_2  orthographic_edit_distance  \\\n",
       "0            amusement  discoveries                          10   \n",
       "1                avril       effect                           6   \n",
       "2           biomorphic    serialize                          10   \n",
       "3              meeting   trendiness                           7   \n",
       "4           formatting     hierarch                           9   \n",
       "...                ...          ...                         ...   \n",
       "49735346      alastair       autumn                           6   \n",
       "49735347  articulation     definite                          10   \n",
       "49735348   suppression     surprise                           6   \n",
       "49735349       keyword    realising                           8   \n",
       "49735350     similarit       widens                           8   \n",
       "\n",
       "          phonetic_edit_distance  \n",
       "0                              9  \n",
       "1                              5  \n",
       "2                              9  \n",
       "3                              9  \n",
       "4                              7  \n",
       "...                          ...  \n",
       "49735346                       6  \n",
       "49735347                      10  \n",
       "49735348                       5  \n",
       "49735349                       7  \n",
       "49735350                       8  \n",
       "\n",
       "[49735351 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homophones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find 10 nearest neighbours for each word\n",
    "for word in words:\n",
    "    #For each word query all the row containing that word\n",
    "    homophones.query(\"word_1 == '%s'\"%(word))\n",
    "    homophones.query(\"word_2 == '%s'\"%(word))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = pd.read_csv('Data/nearest_neighbours.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>orthographic</th>\n",
       "      <th>raw_phonetic</th>\n",
       "      <th>filtered_phonetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quick</td>\n",
       "      <td>('quite', 'trick', 'stick', 'which', 'guide', ...</td>\n",
       "      <td>('clear', 'switch', 'which', 'trick', 'quite',...</td>\n",
       "      <td>('stick', 'clear', 'switch', 'which', 'quite',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>system</td>\n",
       "      <td>('master', 'mister', 'scores', 'issue', 'shift...</td>\n",
       "      <td>('pistol', 'whistle', 'autumn', 'shifted', 'si...</td>\n",
       "      <td>('pistol', 'mister', 'little', 'shifted', 'whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>material</td>\n",
       "      <td>('general', 'master', 'matter', 'metre', 'term...</td>\n",
       "      <td>('control', 'table', 'little', 'mirror', 'stil...</td>\n",
       "      <td>('careful', 'control', 'table', 'mirror', 'whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trends</td>\n",
       "      <td>('twenty', 'things', 'thanks', 'fronts', 'ther...</td>\n",
       "      <td>('ready', 'twenty', 'refers', 'trying', 'keywo...</td>\n",
       "      <td>('ready', 'twenty', 'refers', 'trying', 'keywo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sorry</td>\n",
       "      <td>('sorta', 'scores', 'spongy', 'start', 'forth'...</td>\n",
       "      <td>('start', 'coffee', 'series', 'saying', 'parts...</td>\n",
       "      <td>('series', 'coffee', 'screen', 'stream', 'star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>above</td>\n",
       "      <td>('about', 'those', 'adopt', 'curve', 'close', ...</td>\n",
       "      <td>('about', 'achieve', 'touch', 'receive', 'tong...</td>\n",
       "      <td>('about', 'achieve', 'touch', 'table', 'other'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>edible</td>\n",
       "      <td>('table', 'flexible', 'child', 'guide', 'eithe...</td>\n",
       "      <td>('table', 'possible', 'flexible', 'definite', ...</td>\n",
       "      <td>('possible', 'table', 'above', 'people', 'opti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>flexible</td>\n",
       "      <td>('edible', 'possible', 'please', 'table', 'exc...</td>\n",
       "      <td>('possible', 'edible', 'portable', 'digital', ...</td>\n",
       "      <td>('edible', 'possible', 'portable', 'general', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>places</td>\n",
       "      <td>('plates', 'pages', 'please', 'process', 'pape...</td>\n",
       "      <td>('pages', 'please', 'purposes', 'plates', 'pla...</td>\n",
       "      <td>('pages', 'purposes', 'plates', 'please', 'pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>firewire</td>\n",
       "      <td>('forever', 'their', 'remit', 'report', 'mirro...</td>\n",
       "      <td>('therefore', 'somewhere', 'fourth', 'square',...</td>\n",
       "      <td>('right', 'final', 'somewhere', 'therefore', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word                                       orthographic  \\\n",
       "0       quick  ('quite', 'trick', 'stick', 'which', 'guide', ...   \n",
       "1      system  ('master', 'mister', 'scores', 'issue', 'shift...   \n",
       "2    material  ('general', 'master', 'matter', 'metre', 'term...   \n",
       "3      trends  ('twenty', 'things', 'thanks', 'fronts', 'ther...   \n",
       "4       sorry  ('sorta', 'scores', 'spongy', 'start', 'forth'...   \n",
       "..        ...                                                ...   \n",
       "370     above  ('about', 'those', 'adopt', 'curve', 'close', ...   \n",
       "371    edible  ('table', 'flexible', 'child', 'guide', 'eithe...   \n",
       "372  flexible  ('edible', 'possible', 'please', 'table', 'exc...   \n",
       "373    places  ('plates', 'pages', 'please', 'process', 'pape...   \n",
       "374  firewire  ('forever', 'their', 'remit', 'report', 'mirro...   \n",
       "\n",
       "                                          raw_phonetic  \\\n",
       "0    ('clear', 'switch', 'which', 'trick', 'quite',...   \n",
       "1    ('pistol', 'whistle', 'autumn', 'shifted', 'si...   \n",
       "2    ('control', 'table', 'little', 'mirror', 'stil...   \n",
       "3    ('ready', 'twenty', 'refers', 'trying', 'keywo...   \n",
       "4    ('start', 'coffee', 'series', 'saying', 'parts...   \n",
       "..                                                 ...   \n",
       "370  ('about', 'achieve', 'touch', 'receive', 'tong...   \n",
       "371  ('table', 'possible', 'flexible', 'definite', ...   \n",
       "372  ('possible', 'edible', 'portable', 'digital', ...   \n",
       "373  ('pages', 'please', 'purposes', 'plates', 'pla...   \n",
       "374  ('therefore', 'somewhere', 'fourth', 'square',...   \n",
       "\n",
       "                                     filtered_phonetic  \n",
       "0    ('stick', 'clear', 'switch', 'which', 'quite',...  \n",
       "1    ('pistol', 'mister', 'little', 'shifted', 'whi...  \n",
       "2    ('careful', 'control', 'table', 'mirror', 'whi...  \n",
       "3    ('ready', 'twenty', 'refers', 'trying', 'keywo...  \n",
       "4    ('series', 'coffee', 'screen', 'stream', 'star...  \n",
       "..                                                 ...  \n",
       "370  ('about', 'achieve', 'touch', 'table', 'other'...  \n",
       "371  ('possible', 'table', 'above', 'people', 'opti...  \n",
       "372  ('edible', 'possible', 'portable', 'general', ...  \n",
       "373  ('pages', 'purposes', 'plates', 'please', 'pla...  \n",
       "374  ('right', 'final', 'somewhere', 'therefore', '...  \n",
       "\n",
       "[375 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
