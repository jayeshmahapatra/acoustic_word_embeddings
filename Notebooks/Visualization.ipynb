{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Core Python, Pandas, and kaldi_io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from collections import Counter\n",
    "import kaldi_io\n",
    "\n",
    "#Scikit\n",
    "from sklearn import manifold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import pairwise_distances,average_precision_score\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "\n",
    "#Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "\n",
    "#Torch and utilities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset,DataSet,DataLoader,random_split,ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_on_character_length(matrices,mat_lengths,keys, char_threshold = 5):\n",
    "    '''Takes in matrices and keys. Filters the data by making all keys lowercase, removing words\n",
    "    with number of letters less than a threshold.'''\n",
    "    \n",
    "    print('Length before filtering %d'%(len(keys)))\n",
    "    #Lowercase all keys\n",
    "    keys = list(map(lambda x: x.translate(str.maketrans('', '', string.punctuation)).lower(),keys))\n",
    "    \n",
    "    #Filter if the characters are smaller than the character threshold\n",
    "    matrices,mat_lengths,keys = zip(*filter(lambda x: len(x[2])>=char_threshold, zip(matrices,mat_lengths,keys)))\n",
    "    \n",
    "    matrices,mat_lengths,keys = list(matrices),list(mat_lengths),list(keys)\n",
    "    \n",
    "    print('Length after filtering %d'%(len(keys)))\n",
    "    \n",
    "\n",
    "    return matrices,mat_lengths,keys\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_on_character_frequency(matrices,mat_lengths,keys,frequency_bounds = (0,np.Inf)):\n",
    "    '''Filter words that have frequnecy less than a lower bound threshold or more than an upper bound threshold'''\n",
    "    \n",
    "    print('Length before filtering %d'%(len(keys)))\n",
    "    \n",
    "    #Create a Counter\n",
    "    c = Counter(keys)\n",
    "    \n",
    "    #Get the words whose frequency is below a lower bound threshold or above an upper bound threshold\n",
    "    remove_list = []\n",
    "    \n",
    "    for key,value in c.items():\n",
    "        if value < frequency_bounds[0] or value > frequency_bounds[1]:\n",
    "            remove_list.append(key)\n",
    "            \n",
    "    #Remove the words from the Counter\n",
    "    for word in remove_list:\n",
    "        del c[word]\n",
    "        \n",
    "    #Remove the words from data\n",
    "    matrices,mat_lengths,keys = zip(*filter(lambda x: x[2] not in remove_list, zip(matrices,mat_lengths,keys)))\n",
    "    \n",
    "    \n",
    "    print('Length after filtering %d'%(len(keys)))\n",
    "    \n",
    "    return map(list,(matrices,mat_lengths,keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to truncate and limit dimensionality\n",
    "def truncate_shapes(matrices,mat_lengths,max_length = 100,num_mfcc_features = 40):\n",
    "    \n",
    "    for i, seq in enumerate(matrices):\n",
    "        matrices[i] = matrices[i][:max_length, :num_mfcc_features]\n",
    "        mat_lengths[i] = min(mat_lengths[i], max_length)\n",
    "    \n",
    "    return matrices,mat_lengths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for padding\n",
    "def pad_sequences(x, n_padded, center_padded=True):\n",
    "    \"\"\"Return the padded sequences and their original lengths.\"\"\"\n",
    "    padded_x = np.zeros((len(x), n_padded, x[0].shape[1]))\n",
    "    lengths = []\n",
    "    for i_data, cur_x in enumerate(x):\n",
    "        length = cur_x.shape[0]\n",
    "        if center_padded:\n",
    "            padding = int(np.round((n_padded - length) / 2.))\n",
    "            if length <= n_padded:\n",
    "                padded_x[i_data, padding:padding + length, :] = cur_x\n",
    "            else:\n",
    "                # Cut out snippet from sequence exceeding n_padded\n",
    "                padded_x[i_data, :, :] = cur_x[-padding:-padding + n_padded]\n",
    "            lengths.append(min(length, n_padded))\n",
    "        else:\n",
    "            length = min(length, n_padded)\n",
    "            padded_x[i_data, :length, :] = cur_x[:length, :]\n",
    "            lengths.append(length)\n",
    "    return padded_x, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_key_dicts_and_labels(keys):\n",
    "    '''Arguments:\n",
    "    keys : A list of words corresponding to the mfcc feature matrices\n",
    "    -------------\n",
    "    Returns:\n",
    "    labels : A list of numbers correspoding to the words in the list keys'''\n",
    "    c = Counter(keys)\n",
    "    #print(c)\n",
    "    num_words = len(c.keys())\n",
    "    word_to_num = {}\n",
    "    num_to_word = {}\n",
    "\n",
    "    index = 0\n",
    "    for key in c.keys():\n",
    "        word_to_num[key] = index\n",
    "        num_to_word[index] = key\n",
    "        index+=1\n",
    "\n",
    "    label_list = []\n",
    "    for key in keys:\n",
    "        label_list.append(word_to_num[key])\n",
    "\n",
    "    print('Number of Unique words ',len(c.keys()))\n",
    "    return c,word_to_num,num_to_word,label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "keys = []\n",
    "matrices = []\n",
    "mat_lengths = []\n",
    "\n",
    "#number_list = [9,12,14,18,21,25,27,28]\n",
    "number_list = [9]\n",
    "load_list = ['Data/raw_mfcc_AMI_Segments.%d.scp'%(number) for number in number_list]\n",
    "#load_list = ['Data/word_mfcc_features.ark']\n",
    "\n",
    "for load_file in load_list:\n",
    "    file_keys,file_matrices,file_mat_lengths = [],[],[]\n",
    "    for key,matrix in kaldi_io.read_mat_scp(load_file):\n",
    "    #for key,matrix in kaldi_io.read_mat_ark(load_file):\n",
    "        file_keys.append(key.split('_')[1])\n",
    "        file_matrices.append(matrix)\n",
    "        file_mat_lengths.append(matrix.shape[0])\n",
    "    #Filter the data\n",
    "    file_matrices,file_mat_lengths,file_keys = filter_on_character_length(file_matrices,file_mat_lengths,file_keys,char_threshold = 5)\n",
    "    \n",
    "    #Add to the main list\n",
    "    keys.extend(file_keys)\n",
    "    matrices.extend(file_matrices)\n",
    "    mat_lengths.extend(file_mat_lengths)\n",
    "print(len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Truncate the dimensions of the data\n",
    "matrices,mat_lengths = truncate_shapes(matrices,mat_lengths,max_length=200,num_mfcc_features=40)\n",
    "#Pad the matrices\n",
    "matrices,mat_lengths = pad_sequences(matrices,n_padded = 100,center_padded = True)\n",
    "matrices = np.transpose(matrices,(0,2,1))\n",
    "#Generate keys and labels\n",
    "c,word_to_num,num_to_word,label_list = generate_key_dicts_and_labels(keys)\n",
    "#delete keys and mat_lengths\n",
    "del keys,mat_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.stack(matrices)\n",
    "del matrices\n",
    "#inputs = np.expand_dims(inputs,1)\n",
    "labels = np.array(label_list)\n",
    "del label_list\n",
    "print(inputs.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainval,x_test,y_trainval,y_test = train_test_split(inputs, labels, test_size=0.2, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_val,y_train,y_val = train_test_split(x_trainval,y_trainval,test_size =0.25, random_state = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = torch.tensor(x_train,dtype= torch.float),torch.tensor(y_train, dtype= torch.float)\n",
    "x_val,y_val = torch.tensor(x_val, dtype= torch.float),torch.tensor(y_val, dtype= torch.float)\n",
    "x_test,y_test = torch.tensor(x_test, dtype= torch.float),torch.tensor(y_test, dtype= torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape,y_train.shape)\n",
    "print(x_val.shape,y_val.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, pin_memory = True, drop_last = True)\n",
    "\n",
    "val_ds = TensorDataset(x_val, y_val)\n",
    "val_dl = DataLoader(val_ds, batch_size=bs, pin_memory = True, drop_last = True)\n",
    "\n",
    "test_ds = TensorDataset(x_test, y_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=bs, pin_memory = True, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(40,96,(10))\n",
    "        self.pool = nn.MaxPool1d(3)\n",
    "        self.conv2 = nn.Conv1d(96, 96, (8))\n",
    "        #self.fc1 = nn.Linear(1728, 1024)\n",
    "        self.fc1 = nn.Linear(672, 1024)\n",
    "        self.fc2 = nn.Linear(1024, len(c.keys()))\n",
    "        self.sm = nn.Softmax(dim = 1)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        #print(x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print('Pre')\n",
    "        #print(x.shape)  \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        #print('Post')\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #print(x.shape)\n",
    "        x = F.log_softmax(x,dim=1)\n",
    "        #print(x.shape)\n",
    "        #print(\"Done\")\n",
    "        return x\n",
    "    \n",
    "    def give_embeddings(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        #print(x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print('Pre')\n",
    "        #print(x.shape)  \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        #print('Post')\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(x.shape)\n",
    "        return x.cpu().detach().numpy() if dev.type == 'cuda' else x.detach().numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = SimpleNet()\n",
    "net = SimpleNet()\n",
    "net = net.float()\n",
    "net.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the best model\n",
    "best_model_path = \"./Models/l2_best_model.pth\"\n",
    "net.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = set([num_to_word[y_train[i].item()] for i in range(y_train.shape[0])])\n",
    "val_words = set([num_to_word[y_val[i].item()] for i in range(y_val.shape[0])])\n",
    "test_words = set([num_to_word[y_test[i].item()] for i in range(y_test.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_membership(word):\n",
    "    train_tag = \"Tr\" if word in train_words else \"\"\n",
    "    val_tag = \"|Val\" if word in val_words else \"\"\n",
    "    test_tag = \"|Ts\" if word in test_words else \"\"\n",
    "    return word+\" (%s%s%s)\"%(train_tag,val_tag,test_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_words(word_list,tsne_vectors,labels,rigid_limits = False):\n",
    "    #Get ids of words from labels\n",
    "    num_list = [word_to_num[word] for word in word_list]\n",
    "    ids = np.where(np.isin(labels,np.array(num_list)))\n",
    "    \n",
    "    df_subset = {}\n",
    "    df_subset['tsne-2d-one'] = tsne_vectors[ids][:,0]\n",
    "    df_subset['tsne-2d-two'] = tsne_vectors[ids][:,1]\n",
    "    df_subset['Word'] = [num_to_word[labels[ids][i].item()] for i in range(ids[0].shape[0])]\n",
    "    \n",
    "    #Convert to dataframe\n",
    "    df_subset = pd.DataFrame(df_subset)\n",
    "    #Add membership tags\n",
    "    df_subset['Word'] = df_subset['Word'].apply(add_membership)\n",
    "    \n",
    "    #print(df_subset['tsne-2d-one'].shape)\n",
    "    #print(df_subset['tsne-2d-two'].shape)\n",
    "    #print(len(df_subset['y']))\n",
    "    \n",
    "    #print(ids)\n",
    "    #print(df_subset['y'])\n",
    "    \n",
    "    g = sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"Word\",\n",
    "    data=df_subset,\n",
    "    legend=\"full\",\n",
    "    alpha=0.5)\n",
    "    g.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=1)\n",
    "    \n",
    "    if rigid_limits:\n",
    "        x_coordinate = tsne_vectors[:,0]\n",
    "        y_coordinate = tsne_vectors[:,1]\n",
    "        epsilon = 5\n",
    "        plt.xlim(min(x_coordinate)-epsilon,max(x_coordinate)+epsilon)\n",
    "        plt.ylim(min(y_coordinate)-epsilon,max(y_coordinate)+epsilon)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbors(net,inputs,labels,n_neighbors = 3):\n",
    "    \n",
    "    if dev.type == 'cuda':\n",
    "        inputs = inputs.to(dev, non_blocking = True)\n",
    "    embeddings = net.give_embeddings(inputs)\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm='brute',metric = 'cosine').fit(embeddings)\n",
    "    distances,indices = nbrs.kneighbors(embeddings)\n",
    "    \n",
    "    return distances,indices\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbors_for_word(word,indices,labels):\n",
    "    \n",
    "    num_list = [word_to_num[word]]\n",
    "    ids = np.where(np.isin(labels,np.array(num_list)))\n",
    "    neighbor_indices = indices[ids]\n",
    "    \n",
    "    for i in range(neighbor_indices.shape[0]):\n",
    "        neighboring_words = [num_to_word[labels[neighbor_indices[i,j]]] for j in range(neighbor_indices.shape[1])]\n",
    "        print(neighboring_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_vectors = give_tsne(net,torch.tensor(inputs,dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coordinate = tsne_vectors[:,0]\n",
    "y_coordinate = tsne_vectors[:,1]\n",
    "epsilon = 5\n",
    "print(min(x_coordinate)-epsilon,max(x_coordinate)+epsilon)\n",
    "print(min(y_coordinate)-epsilon,max(y_coordinate)+epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [\"THE\"]\n",
    "visualize_words(word_list,tsne_vectors,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [\"AS\",\"ARE\",\"TWO\",\"SIX\"]\n",
    "visualize_words(word_list,tsne_vectors,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [\"DEALERS\",\"DEALS\",\"BACK\"]\n",
    "visualize_words(word_list,tsne_vectors,labels,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [\"ACCEPTED\",\"ACCEPTS\",\"RADIO\",\"RAIDER\",\"OWNER\",\"OWNERS\"]\n",
    "visualize_words(word_list,tsne_vectors,labels,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [\"NINE\",\"NINETY\",\"ACCEPTED\",\"ACCEPTS\",\"AIMED\",\"AIMING\"]\n",
    "visualize_words(word_list,tsne_vectors,labels,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [\"COUNT\",\"COUNTS\",\"SALE\",\"SUPPORT\",\"SUPPORTED\"]\n",
    "visualize_words(word_list,tsne_vectors,labels,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [\"LATER\",\"LATEST\",\"CLOSE\",\"CLOSING\",\"CLOSED\",\"CLOSELY\"]\n",
    "visualize_words(word_list,tsne_vectors,labels,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances,indices = nearest_neighbors(net,torch.tensor(inputs,dtype=torch.float),labels,n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"SUPPORT\"\n",
    "nearest_neighbors_for_word(word,indices,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"LATER\"\n",
    "nearest_neighbors_for_word(word,indices,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"CLOSING\"\n",
    "nearest_neighbors_for_word(word,indices,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"ACCEPTED\"\n",
    "nearest_neighbors_for_word(word,indices,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"DEALS\"\n",
    "nearest_neighbors_for_word(word,indices,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"RANGE\"\n",
    "nearest_neighbors_for_word(word,indices,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"DAY\"\n",
    "nearest_neighbors_for_word(word,indices,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"CARE\"\n",
    "nearest_neighbors_for_word(word,indices,labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
