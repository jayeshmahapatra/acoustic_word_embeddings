{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Core Python, Pandas, and kaldi_io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from collections import Counter\n",
    "import kaldi_io\n",
    "\n",
    "#Scikit\n",
    "from sklearn import manifold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import pairwise_distances,average_precision_score\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from scipy import stats\n",
    "\n",
    "#Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "\n",
    "#Torch and utilities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset,DataLoader,random_split,ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_on_character_length(matrices,mat_lengths,keys, char_threshold = 5):\n",
    "    '''Takes in matrices and keys. Filters the data by making all keys lowercase, removing words\n",
    "    with number of letters less than a threshold.'''\n",
    "    \n",
    "    print('Length before filtering %d'%(len(keys)))\n",
    "    #Lowercase all keys\n",
    "    keys = list(map(lambda x: x.translate(str.maketrans('', '', string.punctuation)).lower(),keys))\n",
    "    \n",
    "    #Filter if the characters are smaller than the character threshold\n",
    "    matrices,mat_lengths,keys = zip(*filter(lambda x: len(x[2])>=char_threshold, zip(matrices,mat_lengths,keys)))\n",
    "    \n",
    "    matrices,mat_lengths,keys = list(matrices),list(mat_lengths),list(keys)\n",
    "    \n",
    "    print('Length after filtering %d'%(len(keys)))\n",
    "    \n",
    "\n",
    "    return matrices,mat_lengths,keys\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_on_character_frequency(matrices,mat_lengths,keys,frequency_bounds = (0,np.Inf)):\n",
    "    '''Filter words that have frequnecy less than a lower bound threshold or more than an upper bound threshold'''\n",
    "    \n",
    "    print('Length before filtering %d'%(len(keys)))\n",
    "    \n",
    "    #Create a Counter\n",
    "    c = Counter(keys)\n",
    "    \n",
    "    #Get the words whose frequency is below a lower bound threshold or above an upper bound threshold\n",
    "    remove_list = []\n",
    "    \n",
    "    for key,value in c.items():\n",
    "        if value < frequency_bounds[0] or value > frequency_bounds[1]:\n",
    "            remove_list.append(key)\n",
    "            \n",
    "    #Remove the words from the Counter\n",
    "    for word in remove_list:\n",
    "        del c[word]\n",
    "        \n",
    "    #Remove the words from data\n",
    "    matrices,mat_lengths,keys = zip(*filter(lambda x: x[2] not in remove_list, zip(matrices,mat_lengths,keys)))\n",
    "    \n",
    "    \n",
    "    print('Length after filtering %d'%(len(keys)))\n",
    "    \n",
    "    return map(list,(matrices,mat_lengths,keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to truncate and limit dimensionality\n",
    "def truncate_shapes(matrices,mat_lengths,max_length = 100,num_mfcc_features = 40):\n",
    "    \n",
    "    for i, seq in enumerate(matrices):\n",
    "        matrices[i] = matrices[i][:max_length, :num_mfcc_features]\n",
    "        mat_lengths[i] = min(mat_lengths[i], max_length)\n",
    "    \n",
    "    return matrices,mat_lengths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for padding\n",
    "def pad_sequences(x, n_padded, center_padded=True):\n",
    "    \"\"\"Return the padded sequences and their original lengths.\"\"\"\n",
    "    padded_x = np.zeros((len(x), n_padded, x[0].shape[1]))\n",
    "    lengths = []\n",
    "    for i_data, cur_x in enumerate(x):\n",
    "        length = cur_x.shape[0]\n",
    "        if center_padded:\n",
    "            padding = int(np.round((n_padded - length) / 2.))\n",
    "            if length <= n_padded:\n",
    "                padded_x[i_data, padding:padding + length, :] = cur_x\n",
    "            else:\n",
    "                # Cut out snippet from sequence exceeding n_padded\n",
    "                padded_x[i_data, :, :] = cur_x[-padding:-padding + n_padded]\n",
    "            lengths.append(min(length, n_padded))\n",
    "        else:\n",
    "            length = min(length, n_padded)\n",
    "            padded_x[i_data, :length, :] = cur_x[:length, :]\n",
    "            lengths.append(length)\n",
    "    return padded_x, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_key_dicts_and_labels(keys):\n",
    "    '''Arguments:\n",
    "    keys : A list of words corresponding to the mfcc feature matrices\n",
    "    -------------\n",
    "    Returns:\n",
    "    labels : A list of numbers correspoding to the words in the list keys'''\n",
    "    c = Counter(keys)\n",
    "    #print(c)\n",
    "    num_words = len(c.keys())\n",
    "    word_to_num = {}\n",
    "    num_to_word = {}\n",
    "\n",
    "    index = 0\n",
    "    for key in c.keys():\n",
    "        word_to_num[key] = index\n",
    "        num_to_word[index] = key\n",
    "        index+=1\n",
    "\n",
    "    label_list = []\n",
    "    for key in keys:\n",
    "        label_list.append(word_to_num[key])\n",
    "\n",
    "    print('Number of Unique words ',len(c.keys()))\n",
    "    return c,word_to_num,num_to_word,label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "keys = []\n",
    "matrices = []\n",
    "mat_lengths = []\n",
    "\n",
    "load_list = ['Data/feats_cmvn.ark']\n",
    "num_examples = 1000\n",
    "\n",
    "for load_file in load_list:\n",
    "    file_keys,file_matrices,file_mat_lengths = [],[],[]\n",
    "    for i,(key,matrix) in enumerate(kaldi_io.read_mat_ark(load_file)):\n",
    "        file_keys.append(key.split('_')[1])\n",
    "        file_matrices.append(matrix)\n",
    "        file_mat_lengths.append(matrix.shape[0])\n",
    "        if i == num_examples-1:\n",
    "            break\n",
    "            \n",
    "    #Filter the data\n",
    "    file_matrices,file_mat_lengths,file_keys = filter_on_character_length(file_matrices,file_mat_lengths,file_keys,char_threshold = 5)\n",
    "    \n",
    "    #Add to the main list\n",
    "    keys.extend(file_keys)\n",
    "    matrices.extend(file_matrices)\n",
    "    mat_lengths.extend(file_mat_lengths)\n",
    "print(len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Truncate the dimensions of the data\n",
    "matrices,mat_lengths = truncate_shapes(matrices,mat_lengths,max_length=200,num_mfcc_features=40)\n",
    "#Pad the matrices\n",
    "matrices,mat_lengths = pad_sequences(matrices,n_padded = 100,center_padded = True)\n",
    "matrices = np.transpose(matrices,(0,2,1))\n",
    "#Generate keys and labels\n",
    "c,word_to_num,num_to_word,label_list = generate_key_dicts_and_labels(keys)\n",
    "#delete keys and mat_lengths\n",
    "del keys,mat_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
